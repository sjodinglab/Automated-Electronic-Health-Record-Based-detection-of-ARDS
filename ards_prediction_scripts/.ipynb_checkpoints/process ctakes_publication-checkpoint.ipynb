{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='radiology_report' # 'radiology_report' or 'clinical_notes'\n",
    "textfile='' #name of the text data file to be processed. Need to have columns: 'EncounterID','time','NOTE_TEXT','NOTE_ID'\n",
    "PATH1=''  #path of the directory which has the textfile, input_files/publication_50_radiology_ctakes_list.csv, and input_files/publication_250_clinical_notes_ctakes_list.csv\n",
    "PATH2=''  #path of the directory to save all the text notes for ctakes processing\n",
    "PATH3=''  #path of the directory to save all the ctakes xml outputs \n",
    "PATH4=''  #path of the directory to save the ctakes dictionary \n",
    "PATH5=''  #path of the directory to save the ctakes features data \n",
    "ctake_list_data=pd.read_csv(PATH1+'publication_50_radiology_ctakes_list.csv')\n",
    "ctakes_list=ctake_list_data.features.tolist() #list of ctakes features need to be extracted;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the xml file and get cuiid\n",
    "def getcui(filename):    \n",
    "    xmldoc=ET.parse(PATH3+filename+'.xml')\n",
    "\n",
    "    elementids=[]\n",
    "    for k in ['DiseaseDisorderMention','SignSymptomMention','ProcedureMention','MedicationMention',\n",
    "             'AnatomicalSiteMention']:\n",
    "        temp =xmldoc.findall('org.apache.ctakes.typesystem.type.textsem.'+k)\n",
    "        elementids+=temp\n",
    "\n",
    "    posids=[]\n",
    "    negids=[]\n",
    "    for i in elementids:\n",
    "        try: \n",
    "            if i.attrib['polarity']=='-1':\n",
    "                negids.append(i.attrib['_ref_ontologyConceptArr'])\n",
    "            else:\n",
    "                posids.append(i.attrib['_ref_ontologyConceptArr'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    cuiidspos=[]\n",
    "    cuiidsneg=[]\n",
    "    global cuidic\n",
    "    for idd in posids:\n",
    "        for target in xmldoc.findall(\".//uima.cas.FSArray[@_id=\"+\"'\"+str(idd)+\"'\"+\"]\"):\n",
    "            i=target.getchildren()[0].text\n",
    "            for target2 in xmldoc.findall(\".//org.apache.ctakes.typesystem.type.refsem.UmlsConcept[@_id=\"+\"'\"+str(i)+\"'\"+\"]\"):\n",
    "                cuiidspos.append(target2.attrib['cui'])\n",
    "                try:\n",
    "                    cuidic[target2.attrib['cui']]=target2.attrib['preferredText']\n",
    "                except:\n",
    "                    print('************************************',target2.attrib['cui'])\n",
    "                    \n",
    "    for idd in negids:\n",
    "        for target in xmldoc.findall(\".//uima.cas.FSArray[@_id=\"+\"'\"+str(idd)+\"'\"+\"]\"):\n",
    "            i=target.getchildren()[0].text\n",
    "            for target2 in xmldoc.findall(\".//org.apache.ctakes.typesystem.type.refsem.UmlsConcept[@_id=\"+\"'\"+str(i)+\"'\"+\"]\"):\n",
    "                cuiidsneg.append(target2.attrib['cui'])\n",
    "                try:\n",
    "                    cuidic[target2.attrib['cui']]=target2.attrib['preferredText']\n",
    "                except:\n",
    "                    print('************************************',target2.attrib['cui'])\n",
    "                \n",
    "\n",
    "\n",
    "    return cuiidspos,cuiidsneg\n",
    "\n",
    "#funtion to sort big data\n",
    "def sortdf(data,temp,colstosort):\n",
    "\n",
    "    asc=[True]*len(colstosort)\n",
    "    temp=temp.sort_values(colstosort, ascending=asc)\n",
    "\n",
    "    index=temp.index\n",
    "\n",
    "    data=data.reindex(index)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Write text notes to PATH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured=pd.read_csv(PATH1+textfile)\n",
    "unstructured.time=pd.to_datetime(unstructured.time)\n",
    "unstructured=unstructured[['EncounterID','time','NOTE_TEXT','NOTE_ID']]\n",
    "unstructured['file_name']=unstructured['EncounterID']+'_'+unstructured['NOTE_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in unstructured.iterrows():\n",
    "    print(index)\n",
    "    text_file = open(PATH2+row['file_name'], \"w\",encoding='utf-8')\n",
    "    text_file.write(row['NOTE_TEXT'])\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Run Apache Ctakes to process the text notes\n",
    "\n",
    "Open Collection Processing Engine. Follow the instruction here:https://cwiki.apache.org/confluence/display/CTAKES/cTAKES+4.0+User+Install+Guide#cTAKES4.0UserInstallGuide-CollectionProcessingEngine(CPE)\n",
    "\n",
    "In the Collection Processing Collection Configurator, set the input directory as PATH2 and output directory as PATH3\n",
    "\n",
    "Set the Descriptor as \\apache-ctakes-4.0.0\\desc\\ctakes-core\\desc\\collection_reader\\FilesInDirectoryCollectionReader.xml\n",
    "\n",
    "Set Analysis Engine as \\apache-ctakes-4.0.0\\desc\\ctakes-clinical-pipeline\\desc\\analysis_engine\\AggregatePlaintextFastUMLSProcessor.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: After step2 is done, process xml ouputs into ctakes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unstructured['cuipos']=np.nan\n",
    "unstructured['cuipos'] = unstructured['cuipos'].astype(object)\n",
    "unstructured['cuineg']=np.nan\n",
    "unstructured['cuineg'] = unstructured['cuineg'].astype(object)\n",
    "\n",
    "cuidic={}\n",
    "for index,row in unstructured.iterrows():\n",
    "    print(index)\n",
    "    filename=row['file_name']\n",
    "    try:\n",
    "        codespos,codesneg=getcui(filename)\n",
    "    except:\n",
    "        print(filename)\n",
    "        codespos,codesneg=[],[]\n",
    "    unstructured.at[index,'cuipos']=codespos\n",
    "    unstructured.at[index,'cuineg']=codesneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldic=pd.DataFrame(list(cuidic.items()), columns=['cuicode', 'preferredText'])\n",
    "finaldic.to_csv(PATH4+name+'_cuicode_dic_ctakes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured=unstructured[['EncounterID','time','cuipos','cuineg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ctakes_list:\n",
    "    unstructured[f]=np.nan\n",
    "    \n",
    "for index,row in unstructured.iterrows():\n",
    "    print(index)\n",
    "    for cui in row['cuipos']:\n",
    "        if cui in ctakes_list:\n",
    "            unstructured.at[index,cui]=1\n",
    "    for cui in row['cuineg']:\n",
    "        if cui in ctakes_list:\n",
    "            unstructured.at[index,cui]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carry forward\n",
    "unstructured.time=pd.to_datetime(unstructured.time)\n",
    "unstructured=sortdf(unstructured,unstructured[['EncounterID','time']],['EncounterID','time'])\n",
    "for f in ctakes_list:\n",
    "    unstructured[f]=unstructured.groupby(['EncounterID'])[f].ffill()\n",
    "\n",
    "unstructured[ctakes_list] = unstructured[ctakes_list].fillna(value=0)\n",
    "\n",
    "cols=['EncounterID','time']+ctakes_list\n",
    "final=unstructured[cols]\n",
    "\n",
    "final.to_csv(PATH5+name+'_ctakes_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
