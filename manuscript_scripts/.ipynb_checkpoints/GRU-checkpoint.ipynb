{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "import random\n",
    "random.seed(123)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import csv\n",
    "from timeit import default_timer as timer\n",
    "from hyperopt import fmin\n",
    "from hyperopt import Trials\n",
    "from hyperopt import tpe\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import hp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking,GRU,MaxPooling1D,Conv1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pyodbc\n",
    "from datetime import timedelta\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import ast\n",
    "import psutil\n",
    "import timeit\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from sklearn.calibration import calibration_curve\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_intubated=True\n",
    "use_sample_weight=True\n",
    "choose_model='GRU'\n",
    "#what data we want to use\n",
    "file='structured+radiology50+clinical_notes250'\n",
    "#Bayesian optimization: number of iterations to run \n",
    "MAX_EVALS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1='Z:\\patient-adjudication-results\\\\'\n",
    "PATH2='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\final_datasets_alternative\\\\'\n",
    "PATH3='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\'\n",
    "PATH4='Z:\\project-datasets\\ARDS\\ml_algorithms\\model_outputs_alternative\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ards=pd.read_csv(PATH1+'current-ards-review-results_2_25_2020.csv',dtype={'mrn': str})\n",
    "ards.rename(columns={'encounterid':'EncounterID'},inplace=True)\n",
    "ards.loc[ards['ards_time']=='.','ards_time']=np.nan\n",
    "\n",
    "#We've settled on using data binned every 6h for training, and data binned every 2h for validation and testing\n",
    "#This script can run on any training data in the format of 'EncounterID','PatientID','ards','time','sampleweight',features\n",
    "if 'only' in file:\n",
    "    bintrain=0\n",
    "    bintest=0\n",
    "    filename1=PATH2+file+'_train.csv'\n",
    "    filename2=PATH2+file+'_train.csv'\n",
    "else:\n",
    "    filename1=PATH2+file+'_6Htrain.csv'\n",
    "    filename2=PATH2+file+'_2Htrain.csv'\n",
    "    bintrain=int(filename1.split('_')[-1][0])\n",
    "    bintest=int(filename2.split('_')[-1][0])\n",
    "    \n",
    "train_str=pd.read_csv(filename1)\n",
    "train_str2=pd.read_csv(filename2)\n",
    "\n",
    "maxlength=max(train_str.groupby(['EncounterID'])['EncounterID'].transform('size').max()+1,train_str2.groupby(['EncounterID'])['EncounterID'].transform('size').max()+1)\n",
    "\n",
    "#get list of encounters that have been intubated \n",
    "structured=pd.read_csv(PATH2+'structured_data.csv')\n",
    "intubated=structured[structured['support']=='invasive']\n",
    "intubated_encounters=intubated.EncounterID.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model: fitted model\n",
    "#inputx: data to be predicted\n",
    "#inputdata: data to be predicted+true labels\n",
    "def get_threshold(model,inputx,inputdata,valy):\n",
    "    x=inputx.copy()\n",
    "    data=inputdata.copy()\n",
    "    \n",
    "    y_predicted=model.predict(x)\n",
    "    predicted=[]\n",
    "    for i in range(len(valy)):\n",
    "        length=len(valy[i])\n",
    "        predicted.extend(y_predicted[i][:length].flatten())\n",
    "    \n",
    "    #get predicted probability\n",
    "    data['predicted_prob']=predicted\n",
    "    \n",
    "    #get each encounter's max predicted_probability and labels\n",
    "    #ards==1 if the encounter had had ards, otherwise 0\n",
    "    aggregation_functions={'predicted_prob':'max','ards':'max'}\n",
    "    data = data.groupby(['EncounterID']).aggregate(aggregation_functions).reset_index(drop=False)\n",
    "   \n",
    "    #get list of precision, recall, and corresponding thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(data['ards'], data['predicted_prob']) \n",
    "\n",
    "\n",
    "    temp=pd.DataFrame(columns=['precision', 'recall', 'thresholds'])\n",
    "    temp['precision']=precision[: -1]\n",
    "    temp['recall']=recall[: -1]\n",
    "    temp['thresholds']=thresholds\n",
    "    temp=temp.sort_values(['recall'], ascending=[True])\n",
    "    temp=temp[temp['recall']>=0.85]\n",
    "\n",
    "    if len(temp)>0:\n",
    "        final_threshold=temp['thresholds'].iloc[0]\n",
    "    else:\n",
    "        final_threshold=0\n",
    "\n",
    "    return final_threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess only need to be done once!!!\n",
    "def preprocess(inputdata,inputtrain):\n",
    "    data=inputdata.copy().drop('time',1)\n",
    "    train=inputtrain.copy()\n",
    "    trainx=[]\n",
    "    trainy=[]\n",
    "    weight=[]\n",
    "\n",
    "\n",
    "    cols_to_norm = data.drop(['EncounterID','ards','sampleweight'],1).columns.tolist()\n",
    "    \n",
    "    sc = StandardScaler()  \n",
    "    train[cols_to_norm]= sc.fit_transform(train[cols_to_norm])\n",
    "    data[cols_to_norm] =sc.transform(data[cols_to_norm])\n",
    "    \n",
    "    for encounter in data.EncounterID.unique():\n",
    "        t=data[data['EncounterID']==encounter].drop(['EncounterID'],1)\n",
    "        x=t.drop(['ards','sampleweight'],1).to_numpy()\n",
    "        trainx.append(x) \n",
    "        y=np.array(t['ards'])\n",
    "        trainy.append(y)\n",
    "        #add sample weight\n",
    "        weight.append(np.array(t['sampleweight']))\n",
    "        \n",
    "\n",
    "    trainx=np.array(trainx)\n",
    "    trainy=np.array(trainy)\n",
    "    weight=np.array(weight)\n",
    "    \n",
    "    for i in range(len(trainy)):\n",
    "            trainy[i] = trainy[i].reshape(len(trainy[i]), 1)\n",
    "    \n",
    "#     for i in range(len(weight)):\n",
    "#         weight[i] = weight[i].reshape(len(weight[i]), 1)\n",
    "    \n",
    "   \n",
    "    return trainx,trainy,weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model:fitted model\n",
    "#inputx:data to be predicted\n",
    "#inputdata: data to be predicted+labels\n",
    "#threshold: threshold used to get the predicted label. if predicted prob>threshold, predict 1\n",
    "#bootstrap: True if we are applying the function on bootstrapped dataset\n",
    "def getscores(model,inputx,inputdata,valy,threshold,bootstrap=False):\n",
    "    \n",
    "    x=inputx.copy()\n",
    "    data=inputdata.copy()\n",
    "    \n",
    "    y_predicted=model.predict(x)\n",
    "    predicted=[]\n",
    "    for i in range(len(valy)):\n",
    "        length=len(valy[i])\n",
    "        predicted.extend(y_predicted[i][:length].flatten())\n",
    "        \n",
    "    data['predicted_prob']=predicted\n",
    "    \n",
    "    if not bootstrap:\n",
    "        cali_y1, cali_x1 = calibration_curve(data['ards'],data['predicted_prob'],n_bins=10, normalize=True)\n",
    "        \n",
    "        aggregation_functions={'predicted_prob':'max','ards':'max'}\n",
    "        data2 = data.groupby(['EncounterID']).aggregate(aggregation_functions).reset_index(drop=False)\n",
    "\n",
    "        #get calibration curve\n",
    "        cali_y2, cali_x2 = calibration_curve(data2['ards'],data2['predicted_prob'],n_bins=10, normalize=False)\n",
    "\n",
    "     \n",
    "    #get predicted label\n",
    "    data.loc[data['predicted_prob']>=threshold,'predicted']=1\n",
    "    data.loc[data['predicted_prob']<threshold,'predicted']=0\n",
    "\n",
    "    #ENCOUNTER level predition\n",
    "    \n",
    "    aggregation_functions={'predicted':'max','ards':'max'}\n",
    "    dataenc = data.groupby(['EncounterID']).aggregate(aggregation_functions).reset_index(drop=False)\n",
    "    #get list of encounterid that the predicted label and true label are both 1\n",
    "    agree=dataenc[(dataenc['ards']==1 )&(dataenc['predicted']==1)].EncounterID.unique().tolist()\n",
    "    \n",
    "    data=data.sort_values(['EncounterID','time'], ascending=[True,True])\n",
    "    data_hours=data[data['EncounterID'].isin(agree)]\n",
    "    data_hours=data_hours[data_hours['predicted']==1]\n",
    "    \n",
    "\n",
    "    #get time difference\n",
    "    data_hours.time=pd.to_datetime(data_hours.time)\n",
    "    \n",
    "    data_hours.time=pd.to_datetime(data_hours.time)\n",
    "    data_hours=data_hours.groupby(['EncounterID'])['time'].first().reset_index(drop=False)\n",
    "    data_hours=pd.merge(data_hours,ards[['EncounterID','ards_time']],how='left',on='EncounterID')\n",
    "    data_hours.ards_time=pd.to_datetime(data_hours.ards_time)\n",
    "    data_hours['diff']=(((data_hours['time']+timedelta(hours=bintest)))-data_hours['ards_time'])/ np.timedelta64(1, 'h')\n",
    "    data_hours.loc[data_hours['diff']<=0,'earlydiff']=abs(data_hours['diff'])\n",
    "    data_hours.loc[data_hours['diff']>0,'latediff']=abs(data_hours['diff'])\n",
    "    #get median time difference when the prediction was made earlier than ards_time\n",
    "    early_avg_diff=np.nanmedian(data_hours['earlydiff'])\n",
    "    #get median time difference when the prediction was made later than ards_time\n",
    "    late_avg_diff=np.nanmedian(data_hours['latediff'])\n",
    "    #get percentage of early prediction\n",
    "    earlypct=len(data_hours[data_hours['diff']<=0])/len(data_hours)*100\n",
    "    #get percentage of late prediction\n",
    "    latepct=len(data_hours[data_hours['diff']>0])/len(data_hours)*100\n",
    "    \n",
    "    #avg_diff=(round(earlypct,2),round(early_avg_diff,2),round(latepct,2),round(late_avg_diff,2))\n",
    "    avg_diff=np.nanmedian(data_hours['diff'])\n",
    "    \n",
    "#     print(len(data_hours))\n",
    "#     print(len(dataenc[dataenc['ards']==1]))\n",
    "    if not bootstrap:\n",
    "        #save the data used to plot time curve\n",
    "        rows_list = []\n",
    "        for i in range(-48,49):\n",
    "            dic1 = {}\n",
    "            dic1['Time to ards_time(hours)']=i\n",
    "            dic1['Encounter(%)']=len(data_hours[data_hours['diff']<=i])/len(dataenc[dataenc['ards']==1])*100\n",
    "            rows_list.append(dic1)\n",
    "\n",
    "        timecurve = pd.DataFrame(rows_list) \n",
    "    \n",
    "    #get sensitivity, specificity and ppv\n",
    "    CM = confusion_matrix(dataenc['ards'],dataenc['predicted'])\n",
    "    tn, fp, fn, tp =CM.ravel()\n",
    "    \n",
    "    recall=tp/(tp+fn)\n",
    "    recall_ad=(tp+2)/(tp+fn+4)\n",
    "    sensitivity=recall\n",
    "    sen_ci=((sensitivity-1.96*sqrt(sensitivity*(1-sensitivity)/(tp+fn)))*100,(sensitivity+1.96*sqrt(sensitivity*(1-sensitivity)/(tp+fn)))*100)\n",
    "    \n",
    "    sp111=tn/(tn+fp)\n",
    "    sp111_a=(tn+2)/(tn+fp+4)\n",
    "    specificity=sp111\n",
    "    spe_ci=((specificity-1.96*sqrt(specificity*(1-specificity)/(tn+fp)))*100,(specificity+1.96*sqrt(specificity*(1-specificity)/(tn+fp)))*100)\n",
    "    \n",
    "    sp111=tp/(tp+fp)\n",
    "    sp111_a=(tp+2)/(tp+fp+4)\n",
    "    ppv=sp111\n",
    "    ppv_ci=((ppv-1.96*sqrt(ppv*(1-ppv)/(tp+fp)))*100,(ppv+1.96*sqrt(ppv*(1-ppv)/(tp+fp)))*100)\n",
    "    \n",
    "    \n",
    "    if not bootstrap:\n",
    "        return round(sensitivity*100,1), round(specificity*100,1),round(ppv*100,1),avg_diff,(cali_y1,cali_y2),(cali_x1,cali_x2),timecurve\n",
    "    else:\n",
    "        return round(sensitivity*100,1), round(specificity*100,1),round(ppv*100,1),avg_diff\n",
    "    \n",
    "#get bin rocauc and prc score\n",
    "def getroc(model,y,x,valy):\n",
    "    \n",
    "    y_predicted=model.predict(x)\n",
    "    predicted=[]\n",
    "    for i in range(len(valy)):\n",
    "        length=len(valy[i])\n",
    "        predicted.extend(y_predicted[i][:length].flatten())\n",
    "\n",
    "        \n",
    "    y=y.tolist()\n",
    "    \n",
    "    #df=pd.DataFrame(columns=['y','predicted'])\n",
    "    #df['y']=y\n",
    "    #df['predicted']=predicted\n",
    "    #df.to_csv(PATH4+'df.csv',index=False)\n",
    "   \n",
    "    fpr, tpr, threshold = metrics.roc_curve(y, predicted)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    #prc\n",
    "    precision, recall, thresholds = precision_recall_curve(y, predicted) \n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "    \n",
    "    return round(roc_auc,3),round(pr_auc,3)\n",
    "\n",
    "#get encounter rocauc and prc score\n",
    "def getroc_encounter(model,inputx,inputdata,valy,outputname=0,bootstrap=False):\n",
    "    x=inputx.copy()\n",
    "    data=inputdata.copy()\n",
    "    \n",
    "    y_predicted=model.predict(x)\n",
    "    predicted=[]\n",
    "    for i in range(len(valy)):\n",
    "        length=len(valy[i])\n",
    "        predicted.extend(y_predicted[i][:length].flatten())\n",
    "    \n",
    "    data['predicted']=predicted\n",
    "    if outputname!=0 and not bootstrap:\n",
    "        data[['EncounterID','time','ards','predicted']].to_csv(PATH4+outputname+'_predicted_proba.csv',index=False)\n",
    "    \n",
    "    \n",
    "    aggregation_functions={'predicted':'max','ards':'max'}\n",
    "    data = data.groupby(['EncounterID']).aggregate(aggregation_functions).reset_index(drop=False)\n",
    "   \n",
    "    fpr, tpr, threshold = metrics.roc_curve(data['ards'],data['predicted'])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    #save the data to plot rocauc curve\n",
    "    if outputname!=0 and not bootstrap:\n",
    "        output=pd.DataFrame(columns=['fpr','tpr'])\n",
    "        output['fpr']=fpr\n",
    "        output['tpr']=tpr\n",
    "        output.to_csv(PATH4+outputname+'_rocauc.csv',index=False)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(data['ards'], data['predicted']) \n",
    "    #retrieve probability of being 1(in second column of probs_y)\n",
    "    pr_auc = metrics.auc(recall, precision)\n",
    "    \n",
    "    #save the data to plot precision recall curve\n",
    "    if outputname!=0 and not bootstrap:\n",
    "        output=pd.DataFrame(columns=['precision','recall'])\n",
    "        output['precision']=precision\n",
    "        output['recall']=recall\n",
    "        output.to_csv(PATH4+outputname+'_prc.csv',index=False)\n",
    "\n",
    "    if not bootstrap:\n",
    "        #plot Precision-Recall vs Threshold Chart\n",
    "        plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "        plt.plot(thresholds, precision[:-1] , \"b--\", label=\"Precision\")\n",
    "        plt.plot(thresholds, recall[:-1], \"r--\", label=\"Recall\")\n",
    "        plt.ylabel(\"Precision, Recall\")\n",
    "        plt.xlabel(\"Threshold\")\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.ylim([0,1])\n",
    "        plt.show()\n",
    "    \n",
    "  \n",
    "    return round(roc_auc, 3),round(pr_auc,3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit GRU model with a set of hyperparameters, return bin auroc score\n",
    "def tryparams(params,trainx_pad,trainy_pad,valx_pad,valy_pad,valy,valdata_input,traindata_input,trainy,weight,use_sample_weight,draw=False):\n",
    "\n",
    "#     K.set_session(sess)\n",
    "    \n",
    "    print('*********',params)\n",
    "    start = timeit.default_timer()\n",
    "    valdata=valdata_input.copy()\n",
    "    traindata=traindata_input.copy()\n",
    "    \n",
    "    special_value = -1000.0\n",
    "    max_seq_len = maxlength\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=special_value, input_shape=(max_seq_len, trainx_pad.shape[2])))\n",
    "    model.add(GRU(int(params['units1']),activation=params['activation'],dropout= params['dropout'], recurrent_dropout=params['dropout'], return_sequences=True,kernel_regularizer=regularizers.l1(params['l1'])))\n",
    "    model.add(TimeDistributed(Dense(int(params['units2']),kernel_regularizer=regularizers.l1(params['l1']),activation=params['activation'])))\n",
    "    model.add(TimeDistributed(Dense(1,activation='sigmoid')))\n",
    "    opt = adam(lr=params['lr'])\n",
    "    if use_sample_weight:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'],sample_weight_mode=\"temporal\")\n",
    "    else:\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n",
    "    #print(model.summary())\n",
    " \n",
    "   \n",
    "    if use_sample_weight:\n",
    "        history=model.fit(trainx_pad,trainy_pad,validation_data=(valx_pad, valy_pad), epochs=int(params['epochs']), batch_size=int(params['batch_size']),verbose=1,sample_weight=weight,shuffle=False)\n",
    "    else:\n",
    "        history=model.fit(trainx_pad,trainy_pad,validation_data=(valx_pad, valy_pad), epochs=int(params['epochs']), batch_size=int(params['batch_size']),verbose=1,shuffle=False)\n",
    "  \n",
    "    \n",
    "    #get the test scores\n",
    "    try:\n",
    "        rocauc,prauc=getroc(model,valdata['ards'],valx_pad,valy)\n",
    "    except:\n",
    "        rocauc,prauc=0,0\n",
    "    try:\n",
    "        rocauc_encounter,prauc_encounter=getroc_encounter(model,valx_pad,valdata,valy)\n",
    "    except:\n",
    "        rocauc_encounter,prauc_encounter=0,0\n",
    "    try:\n",
    "        #get scores\n",
    "        final_threshold=get_threshold(model,valx_pad,valdata,valy)\n",
    "        sensitivity,specificity, ppv,timediff,caliy,calix,timecurve=getscores(model,valx_pad,valdata,valy,final_threshold)\n",
    "        #print('*************',rocauc,rocauc_encounter,prauc,prauc_encounter,sensitivity, specificity, ppv,timediff)\n",
    "    except:\n",
    "        sensitivity,specificity, ppv,timediff,caliy,calix,timecurve=0,0,0,0,0,0,0\n",
    "        \n",
    "    fold=[rocauc,rocauc_encounter,prauc,prauc_encounter,sensitivity, specificity, ppv,timediff]\n",
    "\n",
    "    \n",
    "        \n",
    "    if draw:\n",
    "        history_dict = history.history\n",
    "        loss_values = history_dict['loss']\n",
    "        val_loss_values = history_dict['val_loss']\n",
    "\n",
    "        epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "        plt.plot(epochs, loss_values, 'b', label='Training loss')  \n",
    "        plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        plt.clf()                       \n",
    "        acc = history_dict['binary_accuracy']\n",
    "        val_acc = history_dict['val_binary_accuracy']\n",
    "\n",
    "        plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "        plt.plot(epochs, val_acc, 'g', label='Validation acc')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.ylim(0.85, 1)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        plt.clf()  \n",
    "        \n",
    "    del model\n",
    "    K.clear_session() \n",
    "    tf.reset_default_graph()\n",
    "    np.random.seed(12)    \n",
    "    random.seed(123)    \n",
    "    tf.set_random_seed(1234) \n",
    "    K.set_session(sess)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    print('Time: ', stop - start)  \n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(process.memory_info().rss)  # in bytes \n",
    "    \n",
    "    return rocauc,fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data and save the prepocessed data so we only need to run preporcessing once\n",
    "def cv_getdata(inputdata,inputdata2=0,testdiff=False):\n",
    "    \n",
    "    data=inputdata.copy()\n",
    "    if testdiff:\n",
    "        data2=inputdata2.copy()\n",
    "    \n",
    "    # test on all the patients no matter they are intubated or not\n",
    "    split=data[['PatientID','ards']].groupby(['PatientID']).sum().reset_index()\n",
    "    split.loc[split['ards']>0,'ards']=1\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=1)\n",
    "    skf.get_n_splits(split['PatientID'], split['ards'])\n",
    "    X,y=split['PatientID'], split['ards']\n",
    "\n",
    "    \n",
    "    dic={'traindata':[],'valdata':[],'trainx':[],'trainy':[],'weight':[],'valx':[],'valy':[]}\n",
    "  \n",
    "    i=1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print('inner',i)\n",
    "        i+=1\n",
    "        ##############\n",
    "        #get patientid for trainset, patientID for testset\n",
    "        trainindex, testindex = X[train_index], X[test_index]\n",
    "\n",
    "        #trainset is used for training in inner cross validation\n",
    "        traindata=data[~(data['PatientID'].isin(testindex))].drop(['PatientID'],1)\n",
    "        dic['traindata'].append(traindata)\n",
    "        #testset is used for testing\n",
    "        if testdiff:\n",
    "            valdata=data2[data2['PatientID'].isin(testindex)].drop(['PatientID'],1)\n",
    "        else:\n",
    "            valdata=data[data['PatientID'].isin(testindex)].drop(['PatientID'],1)\n",
    "        dic['valdata'].append(valdata)\n",
    "        \n",
    "        #preprocess data for GRU\n",
    "        trainx,trainy,weight=preprocess(traindata,traindata)\n",
    "        dic['trainx'].append(trainx)\n",
    "        dic['trainy'].append(trainy)\n",
    "        dic['weight'].append(weight)\n",
    "        valx,valy,none=preprocess(valdata,traindata)\n",
    "        dic['valx'].append(valx)\n",
    "        dic['valy'].append(valy)\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidate(params,dic,use_sample_weight,draw=False):\n",
    "\n",
    "    final=[]\n",
    "    folds=[]\n",
    "\n",
    "    for i in range(5):\n",
    "        print('inner',i)\n",
    "       \n",
    "        traindata=dic['traindata'][i]\n",
    "        valdata=dic['valdata'][i]\n",
    "        trainx=dic['trainx'][i]\n",
    "        trainy=dic['trainy'][i]\n",
    "        weight=dic['weight'][i]\n",
    "        valx=dic['valx'][i]\n",
    "        valy=dic['valy'][i]\n",
    "        \n",
    "        ans=maxlength\n",
    "        \n",
    "        #padding and masking labels\n",
    "        trainy_pad=pad_sequences(trainy,value=-1000,padding='post',maxlen=ans)\n",
    "        valy_pad=pad_sequences(valy,value=-1000,padding='post',maxlen=ans)\n",
    "        weight=pad_sequences(weight,value=-1000,padding='post',maxlen=ans)\n",
    "        \n",
    "        # Padding and Masking training data\n",
    "        special_value = -1000.0\n",
    "        max_seq_len = ans\n",
    "        \n",
    "        trainx_pad = np.full((len(trainx), max_seq_len,trainx[0].shape[1]), fill_value=special_value)\n",
    "        for s, x in enumerate(trainx):\n",
    "            seq_len = x.shape[0]\n",
    "            trainx_pad[s, 0:seq_len, :] = x\n",
    "\n",
    "        valx_pad = np.full((len(valx), max_seq_len, trainx[0].shape[1]), fill_value=special_value)\n",
    "        for s, x in enumerate(valx):\n",
    "            seq_len = x.shape[0]\n",
    "            valx_pad[s, 0:seq_len, :] = x\n",
    "            \n",
    "        #params,trainx_pad,trainy_pad,valx_pad,valy_pad,valy,valdata_input,traindata_input,trainy,weight,draw=False\n",
    "        rocauc,fold=tryparams(params,trainx_pad,trainy_pad,valx_pad,valy_pad,valy,valdata,traindata,trainy,weight,use_sample_weight,draw=draw)\n",
    "             \n",
    "       \n",
    "        final.append(rocauc)\n",
    "        folds.append(fold)\n",
    "        \n",
    "\n",
    "    print('*****************')\n",
    "    print('mean rocauc:',np.mean(final))\n",
    "    print(1-np.mean(final))\n",
    "    \n",
    "    return np.mean(final),folds\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Bayesian optimization to find the best set of hyperparameters\n",
    "## Each iteration is a 5 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective function\n",
    "global  ITERATION\n",
    "ITERATION = 0\n",
    "def objective(params):\n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Perform 5_folds cross validation\n",
    "    score,folds =crossvalidate(params,datadic,use_sample_weight,draw=True)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1-score\n",
    "    \n",
    "   \n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION,run_time])\n",
    "    of_connection.close()\n",
    "    \n",
    "    of_connection2 = open(out_file2, 'a')\n",
    "    writer = csv.writer(of_connection2)\n",
    "#     writer.writerow(['loss', 'params','ITERATION','rocauc','rocauc_encounter','prauc','prauc_encounter','sensitivity', 'specificity','ppv','timediff'])\n",
    "    writer.writerow([loss, params, ITERATION,1,folds[0][0],folds[0][1],folds[0][2],folds[0][3],folds[0][4],folds[0][5],folds[0][6],folds[0][7]])\n",
    "    writer.writerow([loss, params, ITERATION,2,folds[1][0],folds[1][1],folds[1][2],folds[1][3],folds[1][4],folds[1][5],folds[1][6],folds[1][7]])\n",
    "    writer.writerow([loss, params, ITERATION,3,folds[2][0],folds[2][1],folds[2][2],folds[2][3],folds[2][4],folds[2][5],folds[2][6],folds[2][7]])\n",
    "    writer.writerow([loss, params, ITERATION,4,folds[3][0],folds[3][1],folds[3][2],folds[3][3],folds[3][4],folds[3][5],folds[3][6],folds[3][7]])\n",
    "    writer.writerow([loss, params, ITERATION,5,folds[4][0],folds[4][1],folds[4][2],folds[4][3],folds[4][4],folds[4][5],folds[4][6],folds[4][7]])\n",
    "    of_connection2.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Define the search space\n",
    "def uniform_int(name, lower, upper):\n",
    "    # `quniform` returns:\n",
    "    # round(uniform(low, high) / q) * q\n",
    "    return hp.quniform(name, lower, upper, q=1)\n",
    "\n",
    "def loguniform_int(name, lower, upper):\n",
    "    # Do not forget to make a logarithm for the\n",
    "    # lower and upper bounds.\n",
    "    return hp.qloguniform(name, np.log(lower), np.log(upper), q=1)\n",
    "\n",
    "space = {\n",
    "    'batch_size': loguniform_int('batch_size', 100,400 ),\n",
    "    'epochs': uniform_int('epochs',10,30),\n",
    "    'dropout': hp.uniform('dropout', 0, 0.5),\n",
    "    'lr': hp.uniform('lr', 0.0001, 0.001),\n",
    "    'activation':hp.choice('activation', ['relu']),\n",
    "    'l1': hp.uniform('l1', 0.0001, 0.001),\n",
    "    'units1': uniform_int('units1', 100, 300),\n",
    "    'units2': uniform_int('units2', 30, 128),\n",
    "}\n",
    "\n",
    "\n",
    "#Optimization Algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "# Trials object to track progress\n",
    "bayes_trials = Trials()\n",
    "\n",
    "#save result history\n",
    "# File to save first results\n",
    "out_file = PATH4+'trials_'+file+'_'+choose_model+'.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'iteration','train_time'])\n",
    "of_connection.close()\n",
    "\n",
    "out_file2 = PATH4+'trials_'+file+'_'+choose_model+'_5foldoutput.csv'\n",
    "of_connection = open(out_file2, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params','ITERATION','fold','rocauc','rocauc_encounter','prauc','prauc_encounter','sensitivity', 'specificity','ppv','timediff'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run Bayesian optimization\n",
    "\n",
    "#get data\n",
    "datadic=cv_getdata(train_str,inputdata2=train_str2,testdiff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimize\n",
    "start = timeit.default_timer()\n",
    "best = fmin(fn = objective, space = space, algo = tpe_algorithm , \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the 5 fold cross validation result for GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folddata=pd.read_csv( PATH4+'trials_'+file+'_'+choose_model+'_5foldoutput.csv')\n",
    "folddata=folddata.sort_values(by=['loss','fold'],ascending=True).reset_index(drop=True)\n",
    "folddata.loc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the entire training set using the best set of hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data for GRU\n",
    "trainx,trainy,weight=preprocess(train_str.drop('PatientID',1),train_str.drop('PatientID',1))\n",
    "\n",
    "ans=maxlength\n",
    "        \n",
    "#padding and masking labels\n",
    "trainy_pad=pad_sequences(trainy,value=-1000,padding='post',maxlen=ans)\n",
    "weight=pad_sequences(weight,value=-1000,padding='post',maxlen=ans)\n",
    "        \n",
    "# Padding and Masking training data\n",
    "special_value = -1000.0\n",
    "max_seq_len = ans\n",
    "        \n",
    "trainx_pad = np.full((len(trainx), max_seq_len,trainx[0].shape[1]), fill_value=special_value)\n",
    "for s, x in enumerate(trainx):\n",
    "    seq_len = x.shape[0]\n",
    "    trainx_pad[s, 0:seq_len, :] = x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historydata=pd.read_csv( PATH4+'trials_'+file+'_'+choose_model+'.csv')\n",
    "historydata=historydata.sort_values(by='loss',ascending=True).reset_index(drop=True)\n",
    "best=historydata['params'].iloc[0]\n",
    "params=ast.literal_eval(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=special_value, input_shape=(max_seq_len, trainx_pad.shape[2])))\n",
    "model.add(GRU(int(params['units1']),activation=params['activation'],dropout= params['dropout'], recurrent_dropout=params['dropout'], return_sequences=True,kernel_regularizer=regularizers.l1(params['l1'])))\n",
    "model.add(TimeDistributed(Dense(int(params['units2']),kernel_regularizer=regularizers.l1(params['l1']),activation=params['activation'])))\n",
    "model.add(TimeDistributed(Dense(1,activation='sigmoid')))\n",
    "\n",
    "opt = adam(lr=params['lr'])\n",
    "if use_sample_weight:\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'],sample_weight_mode=\"temporal\")\n",
    "    history=model.fit(trainx_pad,trainy_pad,epochs=int(params['epochs']), batch_size=int(params['batch_size']),verbose=1,sample_weight=weight)\n",
    "else:\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['binary_accuracy'])\n",
    "    history=model.fit(trainx_pad,trainy_pad,epochs=int(params['epochs']), batch_size=int(params['batch_size']),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_on_intubated:\n",
    "    #preprocess data for GRU\n",
    "    trainx2,trainy2,weight2=preprocess(train_str2[train_str2['EncounterID'].isin(intubated_encounters)].drop('PatientID',1),train_str.drop('PatientID',1))\n",
    "    train_str2=train_str2[train_str2['EncounterID'].isin(intubated_encounters)].drop('PatientID',1)\n",
    "\n",
    "else:\n",
    "    #preprocess data for GRU\n",
    "    trainx2,trainy2,weight2=preprocess(train_str2.drop('PatientID',1),train_str.drop('PatientID',1))\n",
    "    train_str2=train_str2.drop('PatientID',1)\n",
    "    \n",
    "#padding and masking labels\n",
    "trainy_pad2=pad_sequences(trainy2,value=-1000,padding='post',maxlen=ans)\n",
    "weight2=pad_sequences(weight2,value=-1000,padding='post',maxlen=ans)\n",
    "\n",
    "# Padding and Masking training data\n",
    "special_value = -1000.0\n",
    "max_seq_len = ans\n",
    "\n",
    "trainx_pad2 = np.full((len(trainx2), max_seq_len,trainx2[0].shape[1]), fill_value=special_value)\n",
    "for s, x in enumerate(trainx2):\n",
    "    seq_len = x.shape[0]\n",
    "    trainx_pad2[s, 0:seq_len, :] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get threshold\n",
    "train_threshold=get_threshold(model,trainx_pad2,train_str2,trainy2)\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = PATH4+choose_model+'_'+file+\"_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file1:\n",
    "    pickle.dump(model, file1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocauc,prauc=getroc(model,train_str2['ards'],trainx_pad2,trainy2)\n",
    "\n",
    "rocauc_encounter,prauc_encounter=getroc_encounter(model,trainx_pad2,train_str2,trainy2,outputname=file+' '+choose_model+' train')\n",
    "\n",
    "sensitivity,specificity, ppv,timediff,caliy,calix,timecurve=getscores(model,trainx_pad2,train_str2,trainy2,train_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calibration plot encounter level\n",
    "for i in [0,1]:\n",
    "    fig = plt.figure(1, figsize=(10, 10))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "\n",
    "    ax1.plot(calix[i], caliy[i], \"s-\",\n",
    "                     label=\"%s\" % (choose_model))\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of positives\")\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_title('Calibration plots  (reliability curve)')\n",
    "    plt.show()\n",
    "    if i==0:\n",
    "        fig.savefig(PATH4+file+' '+choose_model+\"_train_calibration_bin.pdf\", bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig(PATH4+file+' '+choose_model+\"_train_calibration_encounter.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'train score: ', rocauc,prauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'train score: ',rocauc_encounter,prauc_encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'train score: ',sensitivity, specificity, ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'train score: ', timediff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_intubated=True\n",
    "choose_model='GRU'\n",
    "file='structured+radiology50+clinical_notes250'\n",
    "\n",
    "\n",
    "PATH1='Z:\\patient-adjudication-results\\\\'\n",
    "PATH2='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\final_datasets_alternative\\\\'\n",
    "PATH3='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\'\n",
    "PATH4='Z:\\project-datasets\\ARDS\\ml_algorithms\\model_outputs_alternative\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ards=pd.read_csv(PATH1+'current-ards-review-results_2_25_2020.csv',dtype={'mrn': str})\n",
    "ards.rename(columns={'encounterid':'EncounterID'},inplace=True)\n",
    "ards.loc[ards['ards_time']=='.','ards_time']=np.nan\n",
    "\n",
    "#We've settled on using data binned every 6h for training, and data binned every 2h for validation and testing\n",
    "#This script can run on any training data in the format of 'EncounterID','PatientID','ards','time','sampleweight',features\n",
    "if 'only' in file:\n",
    "    bintrain=0\n",
    "    bintest=0\n",
    "    filename1=PATH2+file+'_test.csv'\n",
    "    filename2=PATH2+file+'_train.csv'\n",
    "    filename3=PATH2+file+'_train.csv'\n",
    "else:\n",
    "    filename1=PATH2+file+'_2Htest.csv'\n",
    "    filename2=PATH2+file+'_6Htrain.csv'\n",
    "    filename3=PATH2+file+'_2Htrain.csv'\n",
    "    bintest=int(filename1.split('_')[-1][0])\n",
    "    bintrain=int(filename2.split('_')[-1][0])\n",
    "    \n",
    "testdata=pd.read_csv(filename1)\n",
    "traindata=pd.read_csv(filename2)\n",
    "traindata2=pd.read_csv(filename3)\n",
    "\n",
    "maxlength=max(traindata.groupby(['EncounterID'])['EncounterID'].transform('size').max()+1,traindata2.groupby(['EncounterID'])['EncounterID'].transform('size').max()+1)\n",
    "del traindata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of encounters that have been intubated \n",
    "structured=pd.read_csv(PATH2+'structured_data.csv')\n",
    "intubated=structured[structured['support']=='invasive']\n",
    "intubated_encounters=intubated.EncounterID.unique().tolist()\n",
    "if test_on_intubated:\n",
    "    testdata=testdata[testdata['EncounterID'].isin(intubated_encounters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess test data\n",
    "testx,testy,weight=preprocess(testdata.drop('PatientID',1),traindata.drop('PatientID',1))\n",
    "\n",
    "#padding and masking labels\n",
    "testy_pad=pad_sequences(testy,value=-1000,padding='post',maxlen=ans)\n",
    "weight=pad_sequences(weight,value=-1000,padding='post',maxlen=ans)\n",
    "\n",
    "# Padding and Masking testing data\n",
    "special_value = -1000.0\n",
    "max_seq_len = ans\n",
    "\n",
    "testx_pad = np.full((len(testx), max_seq_len,testx[0].shape[1]), fill_value=special_value)\n",
    "for s, x in enumerate(testx):\n",
    "    seq_len = x.shape[0]\n",
    "    testx_pad[s, 0:seq_len, :] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "pkl_filename = PATH4+choose_model+'_'+file+\"_model.pkl\"\n",
    "model= pickle.load(open(pkl_filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get threshold\n",
    "final_threshold=get_threshold(model,testx_pad,testdata,testy)\n",
    "\n",
    "#get the test scores\n",
    "rocauc,prauc=getroc(model,testdata['ards'],testx_pad,testy)\n",
    "rocauc_encounter,prauc_encounter=getroc_encounter(model,testx_pad,testdata,testy,outputname=file+' '+choose_model)\n",
    "sensitivity,specificity, ppv,timediff,caliy,calix,timecurve=getscores(model,testx_pad,testdata,testy,final_threshold)\n",
    "timecurve.to_csv(PATH4+file+' '+choose_model+'_timecurve.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test score: ',rocauc,prauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test score: ',rocauc_encounter,prauc_encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test score: ',sensitivity, specificity,ppv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test score: ',timediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration plot at encounter level\n",
    "for i in [0,1]:\n",
    "    fig = plt.figure(1, figsize=(10, 10))\n",
    "    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "\n",
    "    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "\n",
    "\n",
    "    ax1.plot(calix[i], caliy[i], \"s-\",\n",
    "                     label=\"%s\" % (choose_model))\n",
    "\n",
    "    ax1.set_ylabel(\"Fraction of positives\")\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_title('Calibration plots  (reliability curve)')\n",
    "    plt.show()\n",
    "    if i==0:\n",
    "        fig.savefig(PATH4+file+' '+choose_model+\"_calibration_bin.pdf\", bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig(PATH4+file+' '+choose_model+\"_calibration_encounter.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###time curve\n",
    "filenames=[PATH4+file+' '+choose_model+'_timecurve.csv']\n",
    "n_classes=len(filenames)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(-48, 48, 12))\n",
    "ax.set_yticks(np.arange(0, 100, 10))\n",
    "plt.xlabel('Time to ards_time(hours)')\n",
    "plt.ylabel('Encounter(%)')\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    plt.plot(temp['Time to ards_time(hours)'], temp['Encounter(%)'],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_')[0],color=colors[i],linewidth=0.8,linestyle='-')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(PATH4+file+' '+choose_model+\"_timecurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc auc\n",
    "filenames=[PATH4+file+' '+choose_model+'_rocauc.csv']\n",
    "n_classes=len(filenames)\n",
    "fpr={}\n",
    "tpr={}\n",
    "roc_auc ={}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    fpr[i], tpr[i]=temp['fpr'],temp['tpr']\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "# Plot all ROC curves\n",
    "fig=plt.figure()\n",
    "\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_')[0]+'(area = {0:0.4f})'\n",
    "                   ''.format(roc_auc[i]),\n",
    "             color=colors[i],  linewidth=0.8,linestyle='-')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC AUC Curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "fig.savefig(PATH4+file+' '+choose_model+\"_rocauc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prc\n",
    "filenames=[PATH4+file+' '+choose_model+'_prc.csv']\n",
    "n_classes=len(filenames)\n",
    "precision={}\n",
    "recall={}\n",
    "prc ={}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    precision[i], recall[i]=temp['precision'],temp['recall']\n",
    "    prc[i] = metrics.auc( recall[i],precision[i])\n",
    "    \n",
    "\n",
    "# Plot all ROC curves\n",
    "fig=plt.figure()\n",
    "\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i],precision[i], \n",
    "             label=filenames[i].split('\\\\')[-1].split('_')[0]+'(area = {0:0.4f})'\n",
    "                   ''.format(prc[i]),\n",
    "             color=colors[i],  linewidth=0.8,linestyle='-')\n",
    "\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "fig.savefig(PATH4+file+' '+choose_model+\"_prc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess only need to be done once!!!\n",
    "def ci(inputdata0,inputdata,inputtrain):\n",
    "    data=inputdata.copy().drop('time',1)\n",
    "    train=inputtrain.copy()\n",
    "    trainx=[]\n",
    "    trainy=[]\n",
    "    testdata=[]\n",
    "\n",
    "\n",
    "    cols_to_norm = data.drop(['EncounterID','ards','sampleweight'],1).columns.tolist()\n",
    "    \n",
    "    sc = StandardScaler()  \n",
    "    train[cols_to_norm]= sc.fit_transform(train[cols_to_norm])\n",
    "    data[cols_to_norm] =sc.transform(data[cols_to_norm])\n",
    "    \n",
    "    #preprocess all encounters once\n",
    "    for encounter in data.EncounterID.unique():\n",
    "        t=data[data['EncounterID']==encounter].drop(['EncounterID'],1)\n",
    "        x=t.drop(['ards','sampleweight'],1).to_numpy()\n",
    "        trainx.append(x) \n",
    "        y=np.array(t['ards'])\n",
    "        trainy.append(y)\n",
    "        \n",
    "        testdata.append(inputdata0[inputdata0['EncounterID']==encounter])\n",
    "        \n",
    "    #bootstrap 1000 times\n",
    "    indexlist=list(range(len(data.EncounterID.unique())))\n",
    "    final={'rocauc':[],'prauc':[],'rocauc_enc':[],'prc_enc':[],'sen':[],'spe':[],'ppv':[],'avgdiff':[]}\n",
    "    for i in range(1000):\n",
    "        print(i)\n",
    "        #get the index\n",
    "        indexlist2 = [random.choice(indexlist) for _ in indexlist]\n",
    "        \n",
    "        temp_trainx=[trainx[k] for k in indexlist2]\n",
    "        temp_trainy=[trainy[k] for k in indexlist2]\n",
    "        temp_testdata=[testdata[k] for k in indexlist2]\n",
    "        temp_testdata=pd.concat(temp_testdata)\n",
    "\n",
    "        temp_trainx=np.array(temp_trainx)\n",
    "        temp_trainy=np.array(temp_trainy)\n",
    "\n",
    "        for j in range(len(temp_trainy)):\n",
    "                temp_trainy[j] = temp_trainy[j].reshape(len(temp_trainy[j]), 1)\n",
    "                \n",
    "        #padding and masking labels\n",
    "        testy_pad=pad_sequences(temp_trainy,value=-1000,padding='post',maxlen=ans)\n",
    "\n",
    "        # Padding and Masking testing data\n",
    "        special_value = -1000.0\n",
    "        max_seq_len = ans\n",
    "\n",
    "        testx_pad = np.full((len(temp_trainx), max_seq_len,temp_trainx[0].shape[1]), fill_value=special_value)\n",
    "        for s, x in enumerate(temp_trainx):\n",
    "            seq_len = x.shape[0]\n",
    "            testx_pad[s, 0:seq_len, :] = x\n",
    "            \n",
    "            \n",
    "        rocauc,prauc=getroc(model,temp_testdata['ards'],testx_pad,temp_trainy)\n",
    "        rocauc_encounter,prauc_encounter=getroc_encounter(model,testx_pad,temp_testdata,temp_trainy,outputname=0,bootstrap=True)\n",
    "        sensitivity,specificity, ppv,timediff=getscores(model,testx_pad,temp_testdata,temp_trainy,final_threshold,bootstrap=True)\n",
    "        \n",
    "        final['rocauc'].append(rocauc)\n",
    "        final['prauc'].append(prauc)\n",
    "        final['rocauc_enc'].append(rocauc_encounter)\n",
    "        final['prc_enc'].append(prauc_encounter)\n",
    "        final['sen'].append(sensitivity)\n",
    "        final['spe'].append(specificity)\n",
    "        final['ppv'].append(ppv)\n",
    "        final['avgdiff'].append(timediff)\n",
    "        \n",
    "\n",
    "        \n",
    "    for k in final.keys():\n",
    "        final[k].sort()\n",
    "        final[k]=np.percentile(final[k], [2.5, 97.5])  \n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 95% confidence interval\n",
    "CI=ci(testdata,testdata.drop('PatientID',1),traindata.drop('PatientID',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out 95% confidence interval\n",
    "print('95% confidence interval for test scores')\n",
    "for k in CI.keys():\n",
    "    print(k,' ',CI[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
