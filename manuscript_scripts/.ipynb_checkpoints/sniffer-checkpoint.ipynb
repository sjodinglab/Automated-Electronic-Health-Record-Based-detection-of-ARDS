{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from nltk import tokenize\n",
    "import nltk.sentiment\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_CT=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other values:\n",
    "#'final_datasets_alternative train cohort'\n",
    "#'final_datasets train cohort'\n",
    "#'final_datasets test cohort'\n",
    "teston='final_datasets_alternative test cohort'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1='Z:\\patient-adjudication-results\\\\'\n",
    "PATH2='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\final_datasets\\\\'\n",
    "PATH3='Z:\\project-datasets\\ARDS\\ml_algorithms\\\\'\n",
    "PATH4='Z:\\project-datasets\\ARDS\\ml_algorithms\\model_outputs\\\\'\n",
    "PATH5='Z:\\\\DOCTR-datasets\\\\arf-2016-2017-notes-echo-reports\\\\v3\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in data\n",
    "data_ards=pd.read_csv(PATH1+'current-ards-review-results_2_25_2020.csv',dtype={'mrn': str,'patient_id':str})\n",
    "data_ards.rename(columns={'encounterid':'EncounterID'},inplace=True)\n",
    "\n",
    "finalcohort=pd.read_csv(PATH2+'final_cohort_encounters_V2.csv')\n",
    "finalencounters=finalcohort.EncounterID.tolist()\n",
    "data_ards=data_ards[data_ards['EncounterID'].isin(finalencounters)]\n",
    "data_ards.admitdate=pd.to_datetime(data_ards.admitdate)\n",
    "data_ards.loc[data_ards['ards_time']=='.','ards_time']=np.nan\n",
    "data_ards.ards_time=pd.to_datetime(data_ards.ards_time)\n",
    "\n",
    "correctmrn=pd.read_csv(PATH1+'correct_mrn.csv')\n",
    "data_ards=pd.merge(data_ards,correctmrn[['EncounterID','correct_mrn']],how='left',on='EncounterID')\n",
    "data_ards.loc[pd.notnull(data_ards['mrn'])&pd.notnull(data_ards['correct_mrn'])&(data_ards['mrn']!=data_ards['correct_mrn']),'mrn']=data_ards['correct_mrn']\n",
    "data_ards.loc[data_ards['EncounterID']=='947FB2B0-B009-E611-A8AF-F0921C021BF8','mrn']='100589685'\n",
    "\n",
    "data_xray=pd.read_csv(PATH5+'hpi3555_3197_clone.csv',encoding = \"ISO-8859-1\",dtype={'PAT_MRN_ID': str})\n",
    "structured=pd.read_csv(PATH2+'structured_data.csv')\n",
    "\n",
    "if teston=='final_datasets train cohort':\n",
    "    trainset=data_ards[(data_ards['year']==2016)&(data_ards['not_reviewed']==0)&(data_ards['not_cohort']==0)&(pd.notnull(data_ards['pt_ards']))].EncounterID.unique().tolist()\n",
    "if teston=='final_datasets test cohort':\n",
    "    trainset=data_ards[(data_ards['year']==2017)&(data_ards['not_reviewed']==0)&(data_ards['not_cohort']==0)&(pd.notnull(data_ards['pt_ards']))].EncounterID.unique().tolist()\n",
    "if teston=='final_datasets_alternative train cohort':\n",
    "    date= '2017/07/01'\n",
    "    date= pd.to_datetime(date)\n",
    "    trainset=data_ards[(data_ards['admitdate']<date)&(data_ards['not_reviewed']==0)&(data_ards['not_cohort']==0)&(pd.notnull(data_ards['pt_ards']))].EncounterID.unique().tolist()\n",
    "if teston=='final_datasets_alternative test cohort':\n",
    "    date= '2017/07/01'\n",
    "    date= pd.to_datetime(date)\n",
    "    trainset=data_ards[(data_ards['admitdate']>date)&(data_ards['not_reviewed']==0)&(data_ards['not_cohort']==0)&(pd.notnull(data_ards['pt_ards']))].EncounterID.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include training cohort\n",
    "data_ards=data_ards[data_ards['EncounterID'].isin(trainset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_ards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select relavent columns\n",
    "data_xray=data_xray.rename(columns = {'PAT_MRN_ID':'mrn'})\n",
    "data_xray = data_xray[['ORDER_ID','PROC_CODE','LINE','mrn','ACCESSION_NUM','PAT_NAME','FINALIZING_DTTM','PROC_NAME','NOTE_TEXT']]\n",
    "data_pf = structured[['EncounterID','time','support','pf','sf']]\n",
    "\n",
    "#merge data_rep with data_ards\n",
    "data_pf=pd.merge(data_pf,data_ards,how='left',on='EncounterID')\n",
    "\n",
    "#exclude records of patients not in data_ards\n",
    "data_pf=data_pf[pd.notnull(data_pf['pt_ards'])]\n",
    "\n",
    "#convert columns of timestamp into correct types\n",
    "data_pf.time =  pd.to_datetime(data_pf['time'])\n",
    "\n",
    "data_pf.admitdate=  pd.to_datetime(data_pf['admitdate'])\n",
    "\n",
    "#calculate the difference between record time and admitdate\n",
    "data_pf['diff'] = data_pf['time'] - data_pf['admitdate']\n",
    "\n",
    "# if the record is within 10 days, assign 1\n",
    "data_pf.loc[(data_pf['diff'] <=timedelta(days=10)) & (data_pf['diff'] >=timedelta(days=0)), 'within10days'] = 1\n",
    "\n",
    "#keep all the records within 10 days\n",
    "data_pf=data_pf[data_pf['within10days']==1]\n",
    "\n",
    "data_xray.FINALIZING_DTTM =  pd.to_datetime(data_xray['FINALIZING_DTTM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "data_pf_intubated=data_pf.copy()\n",
    "\n",
    "#only include p/f ratio during intubation\n",
    "data_pf_intubated=data_pf_intubated[data_pf_intubated['support']=='invasive']\n",
    "\n",
    "#sort the data\n",
    "data_pf_intubated=data_pf_intubated.sort_values(['EncounterID', 'time'], ascending=[True, True])\n",
    "\n",
    "#create a dataframe that keeps the start time of intubations\n",
    "tubetime=data_pf_intubated.groupby(\"EncounterID\")[\"time\"].min()\n",
    "tubetime = pd.Series.to_frame(tubetime)\n",
    "tubetime['EncounterID'] = list(tubetime.index)\n",
    "\n",
    "#create a dataframe that keeps the end time of intubations\n",
    "tubetime_end=data_pf_intubated.groupby(\"EncounterID\")[\"time\"].max()\n",
    "tubetime_end = pd.Series.to_frame(tubetime_end)\n",
    "tubetime_end['EncounterID'] = list(tubetime_end.index)\n",
    "\n",
    "#change column names\n",
    "tubetime.columns=['intubated_time','EncounterID']\n",
    "tubetime_end.columns=['intubated_endtime','EncounterID']\n",
    "tubetime=tubetime.reset_index(drop=True)\n",
    "tubetime_end=tubetime_end.reset_index(drop=True)\n",
    "\n",
    "#keep a list of EncounterID of intubated patients\n",
    "intubated_list=data_pf_intubated['EncounterID'].unique().tolist()\n",
    "\n",
    "#if a patient has been intubated, assign 1\n",
    "data_ards_intubated=data_ards.copy()\n",
    "data_ards_intubated.loc[data_ards_intubated['EncounterID'].isin(intubated_list), 'intubated'] = 1\n",
    "\n",
    "data_ards_intubated.loc[~data_ards_intubated['EncounterID'].isin(intubated_list), 'intubated'] = 0\n",
    "\n",
    "#add tubetime and tubetime_end to data_ards\n",
    "data_ards_intubated=pd.merge(data_ards_intubated,tubetime,how='left',on='EncounterID')\n",
    "data_ards_intubated=pd.merge(data_ards_intubated,tubetime_end,how='left',on='EncounterID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of chest xray exams to be included \n",
    "xray_exams=[\"DI CHEST SINGLE VIEW\",\n",
    "\"DI CHEST 2 VIEW\",\n",
    "\"DI CHEST ADULT PICC\",\n",
    "\"XR CHEST PORTABLE 1 VIEW\",\n",
    "\"XR CHEST 2 VIEWS\",\n",
    "\"XR CHEST MORNING ROUTINE PORTABLE\",\n",
    "\"XR CHEST LINE PLACEMENT PORTABLE\",\n",
    "\"XR CHEST PORTABLE 1 VIEW\",\n",
    "\"XR CHESTMORNING ROUTINE PORTABLE\",\n",
    "\"XR CHEST LINE PLACEMENT PORTABLE\",\n",
    "\"DI CHEST 2 VIEW\",\n",
    "\"XR CHEST PICC 1 VIEW\",\n",
    "\"XR CHEST 1 VIEW\",\n",
    "\"XR CHEST 4 OR MORE VIEWS\"]\n",
    "\n",
    "#list of CT exams\n",
    "ct_exams=[\"CT ANGIO CHEST WO AND W CONTRAST\",\n",
    "\"CT THORAX WO IV CONTRAST\",\n",
    "\"CT THORAX WIV CONTRAST\",\n",
    "\"CT CHEST WO CONTRAST\",\n",
    "\"CT CHEST W CONTRAST\",\n",
    "\"CT THORAX WO AND W IV CONTRAST\",\n",
    "\"CT THORAX LOW DOSE SCREENING\",\n",
    "\"CT CHEST W CONTRAST\",\n",
    "\"CT ANGIO CHEST FOR PE\",\n",
    "\"CT CHEST WO CONTRAST\",\n",
    "\"CT THORAX W IV CONTRAST\",\n",
    "\"CT CHEST WO AND W CONTRAST\",\n",
    "\"CT OFC CHEST\",\n",
    "\"CT OFC ANGIO CHEST\",\n",
    "\"CT ANGIO CHEST PELVIS LOWER EXTRM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only include reports of certain exams in the list\n",
    "if include_CT:\n",
    "    data_xray=data_xray[data_xray['PROC_NAME'].isin(xray_exams+ct_exams)]\n",
    "else:\n",
    "    data_xray=data_xray[data_xray['PROC_NAME'].isin(xray_exams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xray=data_xray.sort_values(['mrn','ACCESSION_NUM','ORDER_ID','FINALIZING_DTTM','PROC_CODE','LINE'], ascending=[True,True,True, True,True,True])\n",
    "data_xray=data_xray.reset_index(drop=True)\n",
    "###concatnate text\n",
    "for index, row in data_xray.iterrows():\n",
    "    #print(index)\n",
    "    if row['LINE']==1:\n",
    "        continue\n",
    "    else:   \n",
    "        data_xray.at[int(index-row['LINE']+1),'NOTE_TEXT'] = data_xray['NOTE_TEXT'].iloc[int(index-row['LINE']+1)]+row['NOTE_TEXT']\n",
    "data_xray=data_xray[data_xray['LINE']==1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframes by encounter id and time\n",
    "#dattime is the time p/f ratio was recorded\n",
    "#FINALIZING_DTTM is the time reports were generated\n",
    "data_pf=data_pf.sort_values(['EncounterID', 'time'], ascending=[True, True])\n",
    "data_xray=data_xray.sort_values(['mrn', 'FINALIZING_DTTM'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_ards_intubated[data_ards_intubated['intubated']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_ards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the same data cleaning procedure for intubated data\n",
    "\n",
    "#data_xray_intubated2 include both xray and ct exams\n",
    "data_ards_intubated = data_ards_intubated[data_ards_intubated['intubated']==1]\n",
    "\n",
    "data_pf_intubated=data_pf_intubated.sort_values(['EncounterID', 'time'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of trigger words\n",
    "Bilaterality=[\n",
    "'bilateral',\n",
    "'biapical' ,\n",
    "'bibasilar' ,\n",
    "'widespread ',\n",
    "'diffuse',\n",
    "'perihilar',\n",
    "'parahilar',\n",
    "'multifocal',\n",
    "'extensive'\n",
    "]\n",
    "\n",
    "Infiltrate=[\n",
    "'infiltrates',\n",
    "'opacities',\n",
    "'airspace',\n",
    "'pneumonia',\n",
    "'aspiration'\n",
    "]\n",
    "\n",
    "left=[\n",
    "    'left'\n",
    "]\n",
    "right=[\n",
    "    'right'\n",
    "]\n",
    "phrases=[\n",
    "    'ards','pulmonary edema','congestive heart failure'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allpatients(model=\"Model1_1_1\"):\n",
    "    labels=[]\n",
    "    predicttime=[]\n",
    "\n",
    "    i=0\n",
    "    for index1, row1 in data_ards.iterrows():\n",
    "        #each row in data_ards represents a patient\n",
    "        #print(i)\n",
    "        i+=1\n",
    "        #reset everything for a new patient\n",
    "        label=0\n",
    "        predict_time=0\n",
    "        pf_time=0 # time p/f <=300\n",
    "        xray_time=0 # time reports were flagged\n",
    "        \n",
    "        #select all rows associated with current patient from data_pf\n",
    "        temp_pf=data_pf[data_pf['EncounterID']==row1['EncounterID']]\n",
    "\n",
    "\n",
    "        for index2, row2 in temp_pf.iterrows():\n",
    "            if (row2['pf']<=300):\n",
    "                \n",
    "                if(model==\"Model2_1_1\"):\n",
    "                    #if p/f<=300, select all rows associated with current patient from data_xray\n",
    "                    temp_xray=data_xray[data_xray['mrn']==row2['mrn']]\n",
    "                    #store the time p/f<=300\n",
    "                    pf_time=row2['time']\n",
    "                    flag1=0\n",
    "                    flag2=0\n",
    "                    \n",
    "                    for index3, row3 in temp_xray.iterrows():\n",
    "                        xray_time=row3['FINALIZING_DTTM']\n",
    "                        diff=(row3['FINALIZING_DTTM']-pf_time) / np.timedelta64(1, 'h')\n",
    "\n",
    "                        if(abs(diff)<=24):\n",
    "        \n",
    "\n",
    "                            #if the report was generated within 24h p/f<=300, scan through the report\n",
    "                            note=row3['NOTE_TEXT'].lower()\n",
    "                            if(isinstance(note, str)):\n",
    "                                if((('bilateral' in note) and ('infiltrate' in note))):\n",
    "                                    flag1=1\n",
    "                                    break\n",
    "                                if('edema' in note):\n",
    "                                    flag2=1\n",
    "                                    break\n",
    "\n",
    "\n",
    "                    if(flag1==1 or flag2==1):\n",
    "                        #label ARDS if the either of the trigger words is detected\n",
    "                        label=1\n",
    "                        #pick the earlier time as the system prediction time\n",
    "                        if(diff<0):\n",
    "                            predict_time=pf_time\n",
    "                        else:\n",
    "                            predict_time=xray_time\n",
    "                        break\n",
    "                \n",
    "                elif(model==\"Model1_1_1\"):\n",
    "                    #select all rows associated with current patient from data_pf\n",
    "                    temp_xray=data_xray[data_xray['mrn']==row2['mrn']]\n",
    "                    #store the time p/f<=300\n",
    "                    pf_time=row2['time']\n",
    "                    flag1=0\n",
    "                    flag2=0\n",
    "                    flag33=0\n",
    "\n",
    "                    for index3, row3 in temp_xray.iterrows():\n",
    "                        xray_time=row3['FINALIZING_DTTM']\n",
    "                        diff=(row3['FINALIZING_DTTM']-pf_time) / np.timedelta64(1, 'h')\n",
    "\n",
    "                        #if the report was generated within 24h p/f<=300, scan through the report\n",
    "                        if(abs(diff)<=24):\n",
    "    \n",
    "                            \n",
    "                            note=row3['NOTE_TEXT'].lower()\n",
    "                            if(isinstance(note, str)):\n",
    "                                #convert the report into list of sentences\n",
    "                                sentances=tokenize.sent_tokenize(note)\n",
    "                                flag3_left=0\n",
    "                                flag3_right=0\n",
    "\n",
    "                                for sentance in sentances:\n",
    "                                    sentance_same=0\n",
    "                                    \n",
    "                                    #flag report if Bilaterality and infiltrate were detected in the same sentence\n",
    "                                    if (any(ext in sentance for ext in Bilaterality) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        flag1=1\n",
    "                                    if (any(ext in sentance for ext in phrases)):\n",
    "                                        flag2=1\n",
    "                                    if (any(ext in sentance for ext in left) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        flag3_left=1\n",
    "                                        sentance_same=1\n",
    "                                    if (any(ext in sentance for ext in right) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        if sentance_same==0:\n",
    "                                            flag3_right=1\n",
    "                                #flagg33=1 if left infiltrate and right infiltrate were detected in seperate sentences in a report\n",
    "                                if(flag3_left==1 and flag3_right==1):\n",
    "                                    flag33=1\n",
    "                                    break\n",
    "                                if(flag1==1 or flag2==1):\n",
    "                                    break\n",
    "\n",
    "                    if(flag1==1 or flag2==1 or flag33==1):\n",
    "                        label=1\n",
    "                        if(diff<0):\n",
    "                            predict_time=pf_time\n",
    "                        else:\n",
    "                            predict_time=xray_time\n",
    "                        break\n",
    "        \n",
    "        \n",
    "        \n",
    "        labels.append(label)\n",
    "        predicttime.append(predict_time)\n",
    "    \n",
    "    results=pd.DataFrame(columns = ['EncounterID'])\n",
    "    results['EncounterID']=data_ards['EncounterID']\n",
    "    results[model+'ards']=labels\n",
    "    results[model+'ardstime']=predicttime\n",
    "    results.to_csv(PATH4+model+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intubated_patients(model=\"Model1_2_1\"):\n",
    "    labels=[]\n",
    "    predicttime=[]\n",
    "\n",
    "    i=0\n",
    "    for index1, row1 in data_ards_intubated.iterrows():\n",
    "        #each row in data_ards represents a patient that has been intubated\n",
    "        #print(i)\n",
    "        i+=1\n",
    "        label=0\n",
    "        predict_time=0\n",
    "        pf_time=0\n",
    "        xray_time=0\n",
    "        \n",
    "        #select all rows associated with current patient from data_pf_intubated\n",
    "        # data_pf_intubated only include p/f recorded during intubation\n",
    "        temp_pf=data_pf_intubated[data_pf_intubated['EncounterID']==row1['EncounterID']]\n",
    "\n",
    "\n",
    "        for index2, row2 in temp_pf.iterrows():\n",
    "            #if model is 1-2-3 or 2-2-3, also consider pf_calc\n",
    "            if (row2['pf']<=300):\n",
    "                if('Model2_2_' in model):\n",
    "                    if ('Model2_2_2'==model):\n",
    "                        #model2-2-2 also scan CT reports\n",
    "                        temp_xray=data_xray2[data_xray2['mrn']==row2['mrn']]\n",
    "                    else:\n",
    "                        temp_xray=data_xray[data_xray['mrn']==row2['mrn']]\n",
    "                    pf_time=row2['time']\n",
    "                    flag1=0\n",
    "                    flag2=0\n",
    "                    for index3, row3 in temp_xray.iterrows():\n",
    "                        xray_time=row3['FINALIZING_DTTM']\n",
    "                        diff=(row3['FINALIZING_DTTM']-pf_time) / np.timedelta64(1, 'h')\n",
    "\n",
    "                        if(abs(diff)<=24):\n",
    "                            note=row3['NOTE_TEXT'].lower()\n",
    "                            if(isinstance(note, str)):\n",
    "                                if((('bilateral' in note) and ('infiltrate' in note))):\n",
    "                                    flag1=1\n",
    "                                    break\n",
    "                                if('edema' in note):\n",
    "                                    flag2=1\n",
    "                                    break\n",
    "\n",
    "\n",
    "                    if(flag1==1 or flag2==1):\n",
    "                    #if((('bilateral' in note) and ('infiltrate' in note)) or ('edema' in note) ):\n",
    "                        label=1\n",
    "                        if(diff<0):\n",
    "                            predict_time=pf_time\n",
    "                        else:\n",
    "                            predict_time=xray_time\n",
    "                        break\n",
    "                    \n",
    "                elif ('Model1_2_' in model):\n",
    "                    if ('Model1_2_2'==model):\n",
    "                        #model1-2-2 also scans ct reports\n",
    "                        temp_xray=data_xray2[data_xray2['mrn']==row2['mrn']]\n",
    "                    else:\n",
    "                        temp_xray=data_xray[data_xray['mrn']==row2['mrn']]\n",
    "                    pf_time=row2['time']\n",
    "                    flag1=0\n",
    "                    flag2=0\n",
    "                    flag33=0\n",
    "\n",
    "                    for index3, row3 in temp_xray.iterrows():\n",
    "                        xray_time=row3['FINALIZING_DTTM']\n",
    "                        diff=(row3['FINALIZING_DTTM']-pf_time) / np.timedelta64(1, 'h')\n",
    "\n",
    "                        if(abs(diff)<=24):\n",
    "                            note=row3['NOTE_TEXT'].lower()\n",
    "                            flag3_left=0\n",
    "                            flag3_right=0\n",
    "                            if(isinstance(note, str)):\n",
    "                                sentances=tokenize.sent_tokenize(note)\n",
    "                                #print('------------')\n",
    "                                flag3_left=0\n",
    "                                flag3_right=0\n",
    "\n",
    "                                for sentance in sentances:\n",
    "                                    sentance_same=0\n",
    "\n",
    "                                    if (any(ext in sentance for ext in Bilaterality) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        flag1=1\n",
    "                                    if (any(ext in sentance for ext in phrases)):\n",
    "                                        flag2=1\n",
    "                                    if (any(ext in sentance for ext in left) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        #print('#########')\n",
    "                                        #print('left')\n",
    "                                        #print(sentance)\n",
    "                                        flag3_left=1\n",
    "                                        sentance_same=1\n",
    "                                    if (any(ext in sentance for ext in right) and any(ext in sentance for ext in Infiltrate)):\n",
    "                                        if sentance_same==0:\n",
    "                                            flag3_right=1\n",
    "                                        #print('#########')\n",
    "                                        #print('right')\n",
    "                                        #print(sentance)\n",
    "\n",
    "                                if(flag3_left==1 and flag3_right==1):\n",
    "                                    flag33=1\n",
    "                                    break\n",
    "                                if(flag1==1 or flag2==1):\n",
    "                                    break\n",
    "\n",
    "                    if(flag1==1 or flag2==1 or flag33==1):\n",
    "                        label=1\n",
    "                        if(diff<0):\n",
    "                            predict_time=pf_time\n",
    "                        else:\n",
    "                            predict_time=xray_time\n",
    "                        break\n",
    "        \n",
    "        labels.append(label)\n",
    "        predicttime.append(predict_time)\n",
    "    \n",
    "    results=pd.DataFrame(columns = ['EncounterID'])\n",
    "    results['EncounterID']=data_ards_intubated['EncounterID']\n",
    "    results[model+'ards']=labels\n",
    "    results[model+'ardstime']=predicttime\n",
    "    \n",
    "    \n",
    "    #crate true label time for inrubated patients\n",
    "    #if a patient developed ARDS before they were intubated, assume they continued to have ARDS while intubated. \n",
    "    #when the model is first applied to that patient (at the time they were intubated), \n",
    "    #the model should say they had ARDS.\n",
    "    \n",
    "    data_ards_intubated.loc[data_ards_intubated['ards_time']=='.','ards_time']=None\n",
    "    data_ards_intubated.ards_time =  pd.to_datetime(data_ards_intubated.ards_time)\n",
    "    data_ards_intubated.intubated_time =  pd.to_datetime(data_ards_intubated.intubated_time)\n",
    "    data_ards_intubated.intubated_endtime =  pd.to_datetime(data_ards_intubated.intubated_endtime)\n",
    "     \n",
    "    true_labeltime=[]\n",
    "    for index, row in data_ards_intubated.iterrows():\n",
    "        if row['pt_ards']==1:\n",
    "            if (row['ards_time']!='.'):\n",
    "                #print(row['ards_time'],row['intubated_time'])\n",
    "                if row['ards_time']<row['intubated_time']:\n",
    "                    true_labeltime.append(row['intubated_time'])\n",
    "                else:\n",
    "                    true_labeltime.append(row['ards_time'])\n",
    "            else:\n",
    "                true_labeltime.append(row['intubated_time'])\n",
    "        else:\n",
    "            true_labeltime.append(0)\n",
    "\n",
    "    results['true_labeltime_intubated'] = true_labeltime\n",
    "    \n",
    "    #crate true labels for inrubated patients\n",
    "    data_ards_intubated.loc[data_ards_intubated['ards_time']=='.','ards_time']=None\n",
    "    data_ards_intubated.ards_time =  pd.to_datetime(data_ards_intubated.ards_time)\n",
    "    data_ards_intubated.intubated_endtime =  pd.to_datetime(data_ards_intubated.intubated_endtime)\n",
    "\n",
    "    \n",
    "    truelabels=[]\n",
    "    for index, row in data_ards_intubated.iterrows():\n",
    "        if(row['pt_ards']==1):\n",
    "\n",
    "            if (row['ards_time']!='.'):\n",
    "\n",
    "                #ardstime=time.strptime(row['ards_time'],\"%Y-%m-%d %H:%M\")\n",
    "                #intubatedendtime=time.strptime(row['intubated_endtime'],\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "                #If a patient developed ARDS after the period they were intubated (which is unlikely)\n",
    "                #they should be considered a \"negative case\"\n",
    "                if(row['ards_time']>row['intubated_endtime']):\n",
    "\n",
    "                    #print(\"#######\")\n",
    "                    #print(row['ards_time'])\n",
    "                    #print(row['intubated_endtime'])\n",
    "                    truelabels.append(0)\n",
    "                else:\n",
    "                    truelabels.append(1)\n",
    "\n",
    "            else:\n",
    "                truelabels.append(1)\n",
    "        else:\n",
    "            truelabels.append(0)\n",
    "            \n",
    "    results['true_labels_intubated']=truelabels\n",
    "    \n",
    "    \n",
    "    \n",
    "    results.to_csv(PATH4+model+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-1-1 Azzam, all patients\n",
    "#1-2-1 Azzam, only intubated\n",
    "#2-1-1 Herasevich, all patients\n",
    "#2-2-1 Herasevich, onlyintubated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allpatients(model=\"Model1_1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allpatients(model=\"Model2_1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intubated_patients(model=\"Model1_2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intubated_patients(model=\"Model2_2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data111=pd.read_csv(PATH4+'Model1_1_1.csv')\n",
    "data121=pd.read_csv(PATH4+'Model1_2_1.csv')\n",
    "data211=pd.read_csv(PATH4+'Model2_1_1.csv')\n",
    "data221=pd.read_csv(PATH4+'Model2_2_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=data_ards[['EncounterID','pt_ards','ards_time']]\n",
    "final=final.reset_index()\n",
    "\n",
    "final_intubated=data_ards_intubated[['EncounterID','pt_ards','ards_time']]\n",
    "final_intubated=final_intubated.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['intubated','all']:\n",
    "    if i=='intubated':\n",
    "        truelabels=data221[['EncounterID','true_labels_intubated']]\n",
    "        truetime=data221[['EncounterID','true_labeltime_intubated']]\n",
    "        final_intubated=pd.merge(final_intubated,truelabels,how='left',on='EncounterID')\n",
    "        final_intubated=pd.merge(final_intubated,truetime,how='left',on='EncounterID')\n",
    "\n",
    "        temp121=data121[['EncounterID','Model1_2_1ards','Model1_2_1ardstime']]\n",
    "        temp121.columns=['EncounterID','Model1_2_1ards','Model1_2_1ardstime']\n",
    "        final_intubated=pd.merge(final_intubated,temp121,how='left',on='EncounterID')\n",
    "\n",
    "        temp221=data221[['EncounterID','Model2_2_1ards','Model2_2_1ardstime']]\n",
    "        temp221.columns=['EncounterID','Model2_2_1ards','Model2_2_1ardstime']\n",
    "        final_intubated=pd.merge(final_intubated,temp221,how='left',on='EncounterID')\n",
    "\n",
    "        final_intubated['true_labels_all']=final_intubated['true_labels_intubated']\n",
    "        final_intubated.loc[pd.isnull(final_intubated['true_labels_all']),'true_labels_all']=final_intubated['pt_ards']\n",
    "\n",
    "    elif i=='all':\n",
    "\n",
    "        final['Model1_1_1ards']=data111['Model1_1_1ards']\n",
    "        final['Model1_1_1ardstime']=data111['Model1_1_1ardstime']\n",
    "\n",
    "        final['Model2_1_1ards']=data211['Model2_1_1ards']\n",
    "        final['Model2_1_1ardstime']=data211['Model2_1_1ardstime']\n",
    "\n",
    "        final['true_labels_all']=final['pt_ards']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getscores(data,true,predicted,model,ci=True):\n",
    "    CM = confusion_matrix(true, predicted)\n",
    "    tn, fp, fn, tp =CM.ravel()\n",
    "    \n",
    "    recall=tp/(tp+fn)\n",
    "    recall_ad=(tp+2)/(tp+fn+4)\n",
    "    sensitivity=recall*100\n",
    "    \n",
    "    sp111=tn/(tn+fp)\n",
    "    sp111_a=(tn+2)/(tn+fp+4)\n",
    "    specificity=sp111*100\n",
    "    \n",
    "    sp111=tp/(tp+fp)\n",
    "    sp111_a=(tp+2)/(tp+fp+4)\n",
    "    ppv=sp111*100\n",
    "    \n",
    "    \n",
    "    \n",
    "    #get median time difference in hours\n",
    "\n",
    "#     aggregation_functions={'true_labels_all':'max','Model'+model+'ards':'max','EncounterID':'first'}\n",
    "#     dataenc = data.groupby(['EncounterID']).aggregate(aggregation_functions).reset_index(drop=True)\n",
    "#     agree=dataenc[(dataenc['true_labels_all']==1 )&(dataenc['Model'+model+'ards']==1)].EncounterID.unique().tolist()\n",
    "\n",
    "    agree=data[(data['true_labels_all']==1 )&(data['Model'+model+'ards']==1)].EncounterID.unique().tolist()\n",
    "\n",
    "\n",
    "    temp1=data[data.EncounterID.isin(agree)]\n",
    "    \n",
    "    temp1=temp1.reset_index(drop=True)\n",
    "\n",
    "    temp1.ards_time=pd.to_datetime(temp1.ards_time)\n",
    "   \n",
    "    temp1['Model'+model+'ardstime']=pd.to_datetime(temp1['Model'+model+'ardstime'])\n",
    "\n",
    "    temp1['diff']=(temp1['Model'+model+'ardstime']-temp1['ards_time'])/ np.timedelta64(1, 'h')\n",
    "\n",
    "    temp1.loc[temp1['diff']<=0,'earlydiff']=abs(temp1['diff'])\n",
    "    temp1.loc[temp1['diff']>0,'latediff']=abs(temp1['diff'])\n",
    "    early_avg_diff=np.nanmedian(temp1['earlydiff'])\n",
    "    late_avg_diff=np.nanmedian(temp1['latediff'])\n",
    "    earlypct=len(temp1[temp1['diff']<=0])/len(temp1)*100\n",
    "    latepct=len(temp1[temp1['diff']>0])/len(temp1)*100\n",
    "    \n",
    "#     print(len(temp1))\n",
    "#     print(len(data[data['true_labels_all']==1]))\n",
    "\n",
    "    #timediff=(earlypct,early_avg_diff,latepct,late_avg_diff)\n",
    "    timediff=np.nanmedian(temp1['diff'])\n",
    "    \n",
    "    if not ci:\n",
    "        #save the data used to plot time curve\n",
    "        rows_list = []\n",
    "        for i in range(-48,49):\n",
    "            dic1 = {}\n",
    "            dic1['Time to ards_time(hours)']=i\n",
    "            dic1['Encounter(%)']=len(temp1[temp1['diff']<=i])/len(data[data['true_labels_all']==1])*100\n",
    "            rows_list.append(dic1)\n",
    "\n",
    "        timecurve = pd.DataFrame(rows_list) \n",
    "        timecurve.to_csv(PATH4+'sniffer '+model+'_timecurve.csv')\n",
    "\n",
    "    \n",
    "    return sensitivity, specificity, ppv,timediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(data):\n",
    "    data=data.iloc[np.random.choice(len(data), size=len(data))]\n",
    "    return data\n",
    "\n",
    "def getci(data,model):\n",
    "    i=0\n",
    "    final={'sen':[],'spe':[],'ppv':[],'avgdiff':[]}\n",
    "    while i<=1000:\n",
    "        #print(i)\n",
    "        i+=1\n",
    "        temp=bootstrap(data)\n",
    "        true=temp['true_labels_all']\n",
    "        predicted=temp['Model'+model+'ards']\n",
    "        sensitivity,specificity, ppv,timediff=getscores(temp,true,predicted,model)\n",
    "\n",
    "        final['sen'].append(sensitivity)\n",
    "        final['spe'].append(specificity)\n",
    "        final['ppv'].append(ppv)\n",
    "        final['avgdiff'].append(timediff)\n",
    "    \n",
    "    for k in final.keys():\n",
    "        final[k].sort()\n",
    "        final[k]=np.percentile(final[k], [2.5, 97.5])  \n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all patients Azzam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sensitivity, specificity, ppv, avg time diff\n",
    "getscores(final,final['true_labels_all'],final['Model1_1_1ards'],'1_1_1',ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='1_1_1'\n",
    "filenames=[PATH4+'sniffer '+model+'_timecurve.csv']\n",
    "n_classes=len(filenames)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(-48, 48, 12))\n",
    "ax.set_yticks(np.arange(0, 100, 10))\n",
    "plt.xlabel('Time to ards_time(hours)')\n",
    "plt.ylabel('Encounter(%)')\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    plt.plot(temp['Time to ards_time(hours)'], temp['Encounter(%)'],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_timecurve')[0],color=colors[i],linewidth=0.8,linestyle='-')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(PATH4+'sniffer '+model+\"_timecurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CI\n",
    "CI=getci(final,'1_1_1')\n",
    "print('95% confidence interval')\n",
    "for k in CI.keys():\n",
    "    print(k,' ',CI[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all patients Herasevich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getscores(final,final['true_labels_all'],final['Model2_1_1ards'],'2_1_1',ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='2_1_1'\n",
    "filenames=[PATH4+'sniffer '+model+'_timecurve.csv']\n",
    "n_classes=len(filenames)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(-48, 48, 12))\n",
    "ax.set_yticks(np.arange(0, 100, 10))\n",
    "plt.xlabel('Time to ards_time(hours)')\n",
    "plt.ylabel('Encounter(%)')\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    plt.plot(temp['Time to ards_time(hours)'], temp['Encounter(%)'],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_timecurve')[0],color=colors[i],linewidth=0.8,linestyle='-')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(PATH4+'sniffer '+model+\"_timecurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CI\n",
    "CI=getci(final,'2_1_1')\n",
    "print('95% confidence interval')\n",
    "for k in CI.keys():\n",
    "    print(k,' ',CI[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intubated patients Azzam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getscores(final_intubated,final_intubated['true_labels_all'],final_intubated['Model1_2_1ards'],'1_2_1',ci=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='1_2_1'\n",
    "filenames=[PATH4+'sniffer '+model+'_timecurve.csv']\n",
    "n_classes=len(filenames)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(-48, 48, 12))\n",
    "ax.set_yticks(np.arange(0, 100, 10))\n",
    "plt.xlabel('Time to ards_time(hours)')\n",
    "plt.ylabel('Encounter(%)')\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    plt.plot(temp['Time to ards_time(hours)'], temp['Encounter(%)'],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_timecurve')[0],color=colors[i],linewidth=0.8,linestyle='-')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(PATH4+'sniffer '+model+\"_timecurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CI\n",
    "CI=getci(final_intubated,'1_2_1')\n",
    "print('95% confidence interval')\n",
    "for k in CI.keys():\n",
    "    print(k,' ',CI[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intubated patients Herasevich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getscores(final_intubated,final_intubated['true_labels_all'],final_intubated['Model2_2_1ards'],'2_2_1',ci=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model='2_2_1'\n",
    "filenames=[PATH4+'sniffer '+model+'_timecurve.csv']\n",
    "n_classes=len(filenames)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(-48, 48, 12))\n",
    "ax.set_yticks(np.arange(0, 100, 10))\n",
    "plt.xlabel('Time to ards_time(hours)')\n",
    "plt.ylabel('Encounter(%)')\n",
    "colors=['red','green','blue','orange','purple','gray']\n",
    "for i in range(n_classes):\n",
    "    temp=pd.read_csv(filenames[i])\n",
    "    plt.plot(temp['Time to ards_time(hours)'], temp['Encounter(%)'],\n",
    "             label=filenames[i].split('\\\\')[-1].split('_timecurve')[0],color=colors[i],linewidth=0.8,linestyle='-')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig(PATH4+'sniffer '+model+\"_timecurve.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CI\n",
    "CI=getci(final_intubated,'2_2_1')\n",
    "print('95% confidence interval')\n",
    "for k in CI.keys():\n",
    "    print(k,' ',CI[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
